{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home - BBC News\n"
     ]
    }
   ],
   "source": [
    "options = Options()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    " \n",
    "driver.get(\"https://www.bbc.com/news\")\n",
    "print(driver.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UN says civilians in Gaza feel abandoned, as only 'crumbs' of aid get in\n"
     ]
    }
   ],
   "source": [
    "#here we extract all headers from the articels\n",
    "news_headers=[]\n",
    "def extract_headers():\n",
    "  elements=driver.find_elements(By.CLASS_NAME, 'gs-c-promo-heading__title')\n",
    "  for element in elements:\n",
    "    if element.text:\n",
    "        news_headers.append(element.text)\n",
    "#driver.quit()\n",
    "extract_headers()\n",
    "print(news_headers[0])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "76\n",
      "https://www.bbc.com/news/entertainment-arts-67242822\n"
     ]
    }
   ],
   "source": [
    "news_urls=[]\n",
    "def get_urls():\n",
    " elements_for_url=driver.find_elements(By.CLASS_NAME, 'gs-c-promo-heading')\n",
    " for element in elements_for_url:\n",
    "        news_urls.append(element.get_attribute('href'))\n",
    " print(len(elements_for_url))\n",
    "get_urls()\n",
    "print(len(news_urls))#list with all the urls to the articels. should be equally long to elements_for_url\n",
    "print(news_urls[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'header': \"UN says civilians in Gaza feel abandoned, as only 'crumbs' of aid get in\", 'url': 'https://www.bbc.com/news/live/world-middle-east-67223217'}\n"
     ]
    }
   ],
   "source": [
    "article1 = {\n",
    "  \"header\": news_headers[0],\n",
    "  \"url\": news_urls[0],\n",
    "}\n",
    "print(article1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract text from the whole article, here for one as an example.\n",
    "driver.get(news_urls[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article not found\n",
      "article not found\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "#here we apply the method from the last cell to all articels. This takes approximately 2 minutes with a total of 76 articels today\n",
    "text_contents=[]\n",
    "def extract_contents():\n",
    " for i in range(len(news_urls)):\n",
    "  driver.get(news_urls[i]) #we go to the specific article by using the url\n",
    "  try:\n",
    "   article = driver.find_element(By.TAG_NAME, 'article')\n",
    "   text_contents.append(article.text)\n",
    "  except: #exception if no article element is there. doesnÂ´t happen often, but has to be handled\n",
    "   article = driver.find_element(By.TAG_NAME, 'body')\n",
    "   text_contents.append(article.text)\n",
    "   print(\"article not found\") #in this test, 3 of 73 articels had no article element. \n",
    "extract_contents()\n",
    "print(len(text_contents)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posted at 14:32\n",
      "14:32\n",
      "Israeli military says Hamas using hospitals in Gaza to 'wage war'\n",
      "Reuters\n",
      "Copyright: Reuters\n",
      "Daniel Hagari says Hamas is planning its attacks using a system of tunnels under hospitals such as Al Shifa\n",
      "Image caption: Daniel Hagari says Hamas is planning its attacks using a system of tunnels under hospitals such as Al Shifa\n",
      "We've just been listening to a briefing from the spokesman of the Israel Defense Forces (IDF), Daniel Hagari.\n",
      "He says Hamas \"wages war from hospitals\" in Gaza by using these facilities as \"terror infrastructures\".\n",
      "He makes specific reference to Al Shifa hospital, the largest in the Gaza Strip. He describes an elaborate network of tunnels beneath the building in Gaza City, from which he says attacks can be planned.\n",
      "Hagari says \"hundreds of terrorists fled into the hospital to hide there\" after attacks on Israel on 7 October, and says Israel has intelligence that \"there is fuel in hospitals in Gaza, and Hamas is using it for its terror infrastructures\".\n",
      "He adds that Hamas does this because, he says, the IDF distinguishes between \"terrorists and civilians\" in its attacks. By contrast, he says Hamas is harming both Israeli and Gazan civilians.\n",
      ".\n",
      "Copyright: .\n",
      "The Al Shifa hospital is located in Gaza City\n",
      "Image caption: The Al Shifa hospital is located in Gaza City\n",
      "Article share tools\n",
      "Share\n",
      "View more share options\n",
      "Share this post\n",
      "Copy this link\n",
      "Read more about these links.\n"
     ]
    }
   ],
   "source": [
    "print(text_contents[0\n",
    "])#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By Joel Guinto\n",
      "76\n",
      "['He adds that Hamas does this because, he says, the IDF distinguishes between \"terrorists and civilians\" in its attacks. By contrast, he says Hamas is harming both Israeli and Gazan civilians.', 'By Paul Kirby', 'By Dalia Haidar', 'By Wyre Davies', 'By Sofia Bettiza in Brussels & Robert Greenall in London', 'no author', 'no author', 'By James Gregory & Frank Gardner, security correspondent', 'By Laura Gozzi', 'By Stephen McDonell', 'By Joel Guinto', 'By Paul Glynn, Mark Savage & Ian Youngs', 'By Annabel Rackham', 'no author', 'By Gloria Aradi', 'By Jonathan Holmes & PA Media', 'no author', 'By Jonathan Holmes & PA Media', 'no author', 'By Favour Nunoo & Wycliffe Muia', 'no author', 'By Jonathan Holmes, Clara Bullock & PA News', 'no author', 'no author', 'no author', 'no author', 'no author', 'By Paul Glynn & Mark Savage', 'no author', 'no author', 'no author', 'no author', 'no author', 'no author', 'no author', 'By Holly Honderich & Eloise Alanna', 'By Mark Savage', 'By James Clayton and Shiona McCallum', 'By Nick Marsh', 'no author', 'By Nikhila Henry and Cherylann Mollan', 'By Jean Mackenzie', 'By Stephen McDonell', 'By Laura Gozzi', 'By Paul Glynn, Mark Savage & Ian Youngs', 'By James Gregory & Frank Gardner, security correspondent', 'By Gloria Aradi', 'By Bernd Debusmann Jr', 'By Jake Horton, Joshua Cheetham and Shayan Sardarizadeh', 'By Yvette Tan & Stephen McDonell', 'By Annabel Rackham', 'no author', 'By Rashi Goel', 'By Hilary George-Parkin', 'By Anthony Ham', 'By Natasha Tripney', 'By Zaria Gorvett', 'By Rebecca M Knight', 'By Laura Hall', 'no author', 'no author', 'no author', 'By Shamoon Hafez', 'By Jonathan Agnew', 'By Kal Sajad', 'no author', 'By Stephen McDonell', 'By Laura Gozzi', 'By Paul Glynn, Mark Savage & Ian Youngs', 'By James Gregory & Frank Gardner, security correspondent', 'By Gloria Aradi', 'By Bernd Debusmann Jr', 'By Jake Horton, Joshua Cheetham and Shayan Sardarizadeh', 'By Yvette Tan & Stephen McDonell', 'By Annabel Rackham', 'no author']\n"
     ]
    }
   ],
   "source": [
    "def get_authors(article):\n",
    "    authors = []\n",
    "    lines = article.split('\\n')\n",
    "    for line in lines[:13]:  # Loop through lines from lines[0] to lines[10]\n",
    "        if \"By\" in line:\n",
    "            authors.append(line)\n",
    "    return authors\n",
    "\n",
    "all_authors = []\n",
    "def get_all_authors():\n",
    "    for article in text_contents:\n",
    "        authors = get_authors(article)\n",
    "        if not authors:  # Check if authors is an empty list\n",
    "            all_authors.append(\"no author\")\n",
    "        else:\n",
    "            all_authors.extend(authors)\n",
    "\n",
    "# Print the authors\n",
    "for author in all_authors:\n",
    "    print(author)\n",
    "\n",
    "\n",
    "get_all_authors()\n",
    "print(all_authors[10])\n",
    "print(len(all_authors))\n",
    "print(all_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 hours ago\n",
      "76\n",
      "['no info', '2 hours ago', '15 hours ago', '1 hour ago', '17 hours ago', 'no info', 'no info', '2 hours ago', '17 hours ago', '5 hours ago', '7 hours ago', '22 minutes ago', 'no info', 'no info', '4 hours ago', '13 minutes ago', '16 hours ago', '15 minutes ago', '16 hours ago', '2 hours ago', '6 hours ago', '12 minutes ago', '15 hours ago', 'no info', 'no info', '8 hours ago', '3 minutes ago', '23 hours ago', 'no info', 'no info', 'no info', 'no info', 'no info', 'no info', 'no info', '12 hours ago', '5 hours ago', '15 hours ago', '14 hours ago', '13 hours ago', '15 hours ago', '1 day ago', '5 hours ago', '17 hours ago', '23 minutes ago', '2 hours ago', '4 hours ago', '41 minutes ago', '22 hours ago', '9 hours ago', '2 minutes ago', '16 hours ago', 'no info', 'no info', 'no info', 'no info', 'no info', 'no info', 'no info', 'no info', '7 hours ago', 'no info', 'no info', 'no info', 'no info', '2 hours ago', '5 hours ago', '17 hours ago', '24 minutes ago', '2 hours ago', '4 hours ago', '42 minutes ago', '22 hours ago', '9 hours ago', '2 minutes ago', '16 hours ago']\n"
     ]
    }
   ],
   "source": [
    "def get_published(article):\n",
    "    published = []\n",
    "    lines = article.split('\\n')\n",
    "    for line in lines[:3]:  # Loop through lines from lines[0] to lines[10]\n",
    "        if \"ago\" in line:\n",
    "            published.append(line)\n",
    "    return published\n",
    "\n",
    "all_published = []\n",
    "def get_all_published():\n",
    "    for article in text_contents:\n",
    "        published = get_published(article)\n",
    "        if not published:  # Check if authors is an empty list\n",
    "            all_published.append(\"no info\")\n",
    "        else:\n",
    "            all_published.extend(published)\n",
    "\n",
    "get_all_published()\n",
    "print(all_published[10])\n",
    "print(len(all_published))\n",
    "print(all_published)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no date\n",
      "no date\n",
      "no date\n",
      "no date\n",
      "no date\n",
      "no date\n",
      "no date\n",
      "no date\n",
      "no date\n",
      "no date\n",
      "no date\n",
      "no date\n",
      "no date\n",
      "no date\n",
      "no date\n",
      "no date\n",
      "no date\n",
      "no date\n",
      "no date\n",
      "no date\n",
      "no date\n",
      "no date\n",
      "no date\n",
      "no date\n",
      "no date\n",
      "no date\n",
      "no date\n",
      "no date\n",
      "no date\n",
      "['unknown', '2023-10-27T12:36:28.000Z', '2023-10-26T23:07:09.000Z', '2023-10-27T13:38:34.000Z', '2023-10-26T21:45:28.000Z', 'unknown', 'unknown', '2023-10-27T12:47:08.000Z', '2023-10-26T21:29:56.000Z', '2023-10-27T09:53:02.000Z', '2023-10-27T07:01:04.000Z', '2023-10-27T14:36:06.000Z', '2023-10-27T14:57:42.000Z', 'unknown', '2023-10-27T10:01:15.000Z', '2023-10-27T15:14:23.000Z', '2023-10-26T22:26:19.000Z', '2023-10-27T15:14:23.000Z', '2023-10-26T22:26:19.000Z', '2023-10-27T12:09:35.000Z', '2023-10-27T08:11:05.000Z', '2023-10-27T15:03:27.000Z', '2023-10-26T23:09:24.000Z', 'unknown', 'unknown', 'unknown', 'unknown', '2023-10-26T15:04:36.000Z', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', '2023-10-27T02:21:15.000Z', '2023-10-27T09:12:53.000Z', '2023-10-26T23:06:08.000Z', '2023-10-27T00:18:50.000Z', '2023-10-27T01:29:11.000Z', '2023-10-26T23:16:59.000Z', '2023-10-25T21:56:52.000Z', '2023-10-27T09:53:02.000Z', '2023-10-26T21:29:56.000Z', '2023-10-27T14:36:06.000Z', '2023-10-27T12:47:08.000Z', '2023-10-27T10:01:15.000Z', '2023-10-27T14:18:33.000Z', '2023-10-26T16:55:10.000Z', '2023-10-27T05:42:47.000Z', '2023-10-27T14:57:42.000Z', '2023-10-26T22:26:19.000Z', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', '2023-10-27T09:53:02.000Z', '2023-10-26T21:29:56.000Z', '2023-10-27T14:36:06.000Z', '2023-10-27T12:47:08.000Z', '2023-10-27T10:01:15.000Z', '2023-10-27T14:18:33.000Z', '2023-10-26T16:55:10.000Z', '2023-10-27T05:42:47.000Z', '2023-10-27T15:36:50.000Z', '2023-10-26T22:26:19.000Z']\n"
     ]
    }
   ],
   "source": [
    "time=[]\n",
    "for i in range(len(news_urls)):\n",
    " driver.get(news_urls[i])\n",
    " try:\n",
    "  time_element=driver.find_element(By.XPATH, \"//*[@id='main-content']/article/header/div[1]/ul/div/li/div[2]/span/span/time\")\n",
    "  date=(time_element.get_attribute('datetime'))\n",
    "  time.append(date)\n",
    " except:\n",
    "   date='unknown'\n",
    "   time.append(date)\n",
    "   print('no date')\n",
    "print(time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unknown', '2023-10-27T12:36:28.000Z', '2023-10-26T23:07:09.000Z', '2023-10-27T13:38:34.000Z', '2023-10-26T21:45:28.000Z', 'unknown', 'unknown', '2023-10-27T12:47:08.000Z', '2023-10-26T21:29:56.000Z', '2023-10-27T09:53:02.000Z', '2023-10-27T07:01:04.000Z', '2023-10-27T14:36:06.000Z', '2023-10-27T14:57:42.000Z', 'unknown', '2023-10-27T10:01:15.000Z', '2023-10-27T15:14:23.000Z', '2023-10-26T22:26:19.000Z', '2023-10-27T15:14:23.000Z', '2023-10-26T22:26:19.000Z', '2023-10-27T12:09:35.000Z', '2023-10-27T08:11:05.000Z', '2023-10-27T15:03:27.000Z', '2023-10-26T23:09:24.000Z', 'unknown', 'unknown', 'unknown', 'unknown', '2023-10-26T15:04:36.000Z', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', '2023-10-27T02:21:15.000Z', '2023-10-27T09:12:53.000Z', '2023-10-26T23:06:08.000Z', '2023-10-27T00:18:50.000Z', '2023-10-27T01:29:11.000Z', '2023-10-26T23:16:59.000Z', '2023-10-25T21:56:52.000Z', '2023-10-27T09:53:02.000Z', '2023-10-26T21:29:56.000Z', '2023-10-27T14:36:06.000Z', '2023-10-27T12:47:08.000Z', '2023-10-27T10:01:15.000Z', '2023-10-27T14:18:33.000Z', '2023-10-26T16:55:10.000Z', '2023-10-27T05:42:47.000Z', '2023-10-27T14:57:42.000Z', '2023-10-26T22:26:19.000Z', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', '2023-10-27T09:53:02.000Z', '2023-10-26T21:29:56.000Z', '2023-10-27T14:36:06.000Z', '2023-10-27T12:47:08.000Z', '2023-10-27T10:01:15.000Z', '2023-10-27T14:18:33.000Z', '2023-10-26T16:55:10.000Z', '2023-10-27T05:42:47.000Z', '2023-10-27T15:36:50.000Z', '2023-10-26T22:26:19.000Z']\n"
     ]
    }
   ],
   "source": [
    "print(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
